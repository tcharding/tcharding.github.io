<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog-rsses on Tobin Harding</title>
    <link>/blog/index.xml</link>
    <description>Recent content in Blog-rsses on Tobin Harding</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Nov 2016 08:29:33 +1100</lastBuildDate>
    <atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Heap Data Structure in Golang</title>
      <link>/blog/heap/</link>
      <pubDate>Thu, 10 Nov 2016 08:29:33 +1100</pubDate>
      
      <guid>/blog/heap/</guid>
      <description>&lt;p&gt;A heap is a data structure that supports the operations &lt;em&gt;insert&lt;/em&gt; and
&lt;em&gt;extract&lt;/em&gt;. Heaps typically come in two varieties, &lt;em&gt;min heap&lt;/em&gt; (for extracting the
minimum value) and &lt;em&gt;max heap&lt;/em&gt;. A heap is built using a binary tree where each
node is said to &lt;em&gt;dominate&lt;/em&gt; the nodes below it. The meaning of dominate depends
on the type of heap being implemented, for a &lt;em&gt;min heap&lt;/em&gt; the key of each node is
&lt;em&gt;less&lt;/em&gt; than the keys of both of child nodes.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;From here on, without loss of generality, we will talk about a heap of integers
(keys) ignoring satellite data that may or may not be associated with each
integer key. &lt;em&gt;Node&lt;/em&gt; and &lt;em&gt;key&lt;/em&gt; will therefore be used interchangeably.&lt;/p&gt;

&lt;p&gt;Like a binary search tree a heap can be implemented using a linked data
structure. There is however, a nifty method of implementing a heap using an
array, thereby reducing the memory requirements since there are no pointers to
store. We store the data as an array of keys and use the index of the keys to
implicitly satisfy the role of pointers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The root node is stored at index 1 and all operations are 1-indexed&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For node at index &lt;em&gt;k&lt;/em&gt; the left child can be found at index &lt;em&gt;2k&lt;/em&gt; and the
right child at index &lt;em&gt;2k + 1&lt;/em&gt;. (Quite clearly, checks must be made prior to
access that an index lies within the underlying array).&lt;/p&gt;

&lt;p&gt;One additional limitation must be placed on the tree, that it is &lt;em&gt;complete&lt;/em&gt;, i.e
all levels of the tree are full with the possible exception of the last level,
and if the last level is not full all nodes are as far to the left as
possible. This limitation results in an array with no holes in it.&lt;/p&gt;

&lt;p&gt;A heap as just described may be defined in Go as such;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type heap struct {
	xs []int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We wrap the array inside a struct to abstract the implementation and limit
access to the functions that we define. Care must be taken
to remember that the heap is 1-indexed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h *heap) Len() int {
	return len(h.xs) - 1 // heap is 1-indexed
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Insertion of a key into a heap can be achieved by adding the key to the end of
the underlying array. Whilst maintaining the structure of the heap this may
violate the &lt;em&gt;heap property&lt;/em&gt; of the parent of the newly inserted key, namely the
parent of the newly inserted key may not be dominant. The heap property for the
parent node can be restored by swapping the newly inserted child node with the
parent. This may in turn, result in the parent above violating the heap
property. We can continue this &lt;em&gt;bubbling&lt;/em&gt; of a node to successively higher nodes
until the heap property is restored. When swapping a node with the parent node
we need not consider the sibling node since if a node dominates the parent then
by definition it dominates the other sibling also.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Insert x into the heap
func (h *heap) Insert(x int) {
	(*h).xs = append(h.xs, x)
	h.bubbleUp(len(h.xs) - 1)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that parenthesis are required to dereference the heap pointer in order to save the
return value of &lt;code&gt;append()&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h *heap) bubbleUp(k int) {
	p, ok := parent(k)
	if !ok {
		return // k is root node
	}
	if h.xs[p] &amp;gt; h.xs[k] {
		h.xs[k], h.xs[p] = h.xs[p], h.xs[k]
		h.bubbleUp(p)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function terminates when either the node is in place or it has reached the
root position.&lt;/p&gt;

&lt;p&gt;We define functions for manipulating indices as described above;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// get index of parent of node at index k
func parent(k int) (int, bool) {
	if k == 1 {
		return 0, false
	}
	return k / 2, true
}

// get index of left child of node at index k
func left(k int) int {
	return 2 * k
}

// get index of right child of node at index k
func right(k int) int {
	return 2*k + 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are now ready to extract the key for which our heap was designed (minimum
or maximum). This key is clearly at index 1, extracting this key however, leaves a hole which
must be filled. Swapping the last key of the array into the hole restores the
heap structure but once again may violate the &lt;em&gt;heap property&lt;/em&gt;. In a similar
fashion to insertion we can restore the heap property by bubbling this node down
the tree until it is either a leaf node or no longer violates the heap
property. In doing this we must consider both child nodes and swap any
non-dominant parent node with the child node that is &lt;em&gt;most&lt;/em&gt; dominant in order for
the heap property of these three nodes to be maintained.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ExtractMin: get minimum value of heap
// and remove value from heap
func (h *heap) ExtractMin() (int, bool) {
	if h.Len() == 0 {
		return 0, false
	}
	v := h.xs[1]
	h.xs[1] = h.xs[h.Len()]
	(*h).xs = h.xs[:h.Len()]
	h.bubbleDown(1)
	return v, true
}
    
func (h *heap) bubbleDown(k int) {
	min := k
	c := left(k)

	// find index of minimum value (k, k&#39;s left child, k&#39;s right child)
	for i := 0; i &amp;lt; 2; i++ {
		if (c + i) &amp;lt;= h.Len() {
			if h.xs[min] &amp;gt; h.xs[c+i] {
				min = c + i
			}
		}
	}
	if min != k {
		h.xs[k], h.xs[min] = h.xs[min], h.xs[k]
		h.bubbleDown(min)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Caution is again needed here since the array indexing and loop conditionals are
unusual because of the 1-indexing.&lt;/p&gt;

&lt;p&gt;See Github for complete
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/heaps/minInt&#34;&gt;source code&lt;/a&gt; and tests.&lt;/p&gt;

&lt;h3 id=&#34;final-note&#34;&gt;Final Note&lt;/h3&gt;

&lt;p&gt;This implementation is based on the text &lt;em&gt;The Algorithm Design
Manual&lt;/em&gt; [Ski08]. In this, the author Steven S. Skiena makes an interesting
observation on the construction of a heap. At first glance one may think to
construct a heap by repeated calls to &lt;code&gt;insert()&lt;/code&gt;. Inserting into a heap (like
any balanced tree) takes O(log &lt;em&gt;n&lt;/em&gt;)), so heap construction in this manner has
worst case running time of O(&lt;em&gt;n&lt;/em&gt; log &lt;em&gt;n&lt;/em&gt;). We can do better, Skiena notes, if we
observe that a &lt;em&gt;full&lt;/em&gt;, &lt;em&gt;complete&lt;/em&gt; tree of &lt;em&gt;n&lt;/em&gt; nodes has &lt;em&gt;n/2&lt;/em&gt; leaf nodes. These
leaf nodes may be considered as sub-trees that maintain the heap property (since
they have only a single node). If then, we base a heap on any array we need only
&lt;em&gt;bubble up&lt;/em&gt; &lt;em&gt;n/2&lt;/em&gt; nodes in order to achieve a heap for which the heap property
holds. This still gives an &lt;em&gt;upper bound&lt;/em&gt; of O(&lt;em&gt;n&lt;/em&gt; log &lt;em&gt;n&lt;/em&gt;), however Skiena goes
on to show that this leads to a &lt;em&gt;not quite geometric&lt;/em&gt; series that he then
assures us quickly converges to linear. He does however, caution us that this
benefit may not be that useful if the algorithm we plan to use our heap for is
not governed by the construction (i.e heapsort will still run in O(&lt;em&gt;n&lt;/em&gt; log
&lt;em&gt;n&lt;/em&gt;)).&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deque Data Structure in Golang</title>
      <link>/blog/deque/</link>
      <pubDate>Tue, 08 Nov 2016 11:14:55 +1100</pubDate>
      
      <guid>/blog/deque/</guid>
      <description>&lt;p&gt;A deque is type of queue which enables adding and removing items from both
ends. Deque ends have such names as &lt;em&gt;left&lt;/em&gt;/&lt;em&gt;right&lt;/em&gt;, &lt;em&gt;front&lt;/em&gt;/&lt;em&gt;rear&lt;/em&gt; or, as we
will use here, &lt;em&gt;front&lt;/em&gt; and &lt;em&gt;back&lt;/em&gt;. The &lt;em&gt;add/remove&lt;/em&gt; operations on a deque are
typically called &lt;em&gt;enqueue&lt;/em&gt; and &lt;em&gt;dequeue&lt;/em&gt;. For ease of explanation but without loss
of generality, we limit discussion to a deque of integers.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;This gives us the following;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Deque struct {
	// Has unexported fields.
}

func (d *Deque) DequeueB() (int, bool)
func (d *Deque) DequeueF() (int, bool)
func (d *Deque) EnqueueB(x int)
func (d *Deque) EnqueueF(x int)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One method of implementing a deque is to use two stacks, one representing the
front of the deque and the other representing the back of the deque. &lt;em&gt;Enqueueing&lt;/em&gt;
and &lt;em&gt;dequeueing&lt;/em&gt; then become simply a matter of &lt;em&gt;pushing&lt;/em&gt; or &lt;em&gt;popping&lt;/em&gt; to, or from, the
appropriate stack. . We will use a simple stack, supporting the operations push, pop, and
length. Previous blog &lt;a href=&#34;../stack&#34;&gt;post&lt;/a&gt; on implementing stacks in Golang.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type stack []int

// push a new integer onto the stack
func (s *stack) push(x int) {
	*s = append(*s, x)
}

// pop: remove and return top element of stack, return false if stack is empty
func (s *stack) pop() (int, bool) {
	if s.len() == 0 {
		return 0, false
	}

	i := len(*s) - 1
	x := (*s)[i]
	*s = (*s)[:i]

	return x, true
}

func (s *stack) len() int {
	return len(*s)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By now, the astute reader will be asking what happens when one stack becomes
empty and a further request comes to deque from that end. The solution to this
dilemma presents the only complexity in this implementation of a deque. Each
time an item is added to, or removed from, the deque we balance the two stacks to
maintain the invariant that while there are 2 or more items, each stack holds at
least one third as many items as the other. In code, that is;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// balance stacks if needed
func (d *Deque) balance() {
	small, big := order(&amp;amp;d.front, &amp;amp;d.back)
	if small.len() == 0 &amp;amp;&amp;amp; big.len() == 1 {
		return
	}
	if 3*d.front.len() &amp;lt; d.back.len() ||
		3*d.back.len() &amp;lt; d.front.len() {
		d.rebalance()
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;order()&lt;/code&gt; simply gives us the stacks back in order of size. Ignoring the
implementation of &lt;code&gt;rebalance()&lt;/code&gt; and time complexity for now, we have a deque that
maintains two &lt;em&gt;&amp;lsquo;balanced&amp;rsquo;&lt;/em&gt; stacks, one holding items for the front of the deque
and the other holding items for the back of the deque. We can enqueue and
dequeue from both ends.&lt;/p&gt;

&lt;h2 id=&#34;balancing-the-deque&#34;&gt;balancing the deque&lt;/h2&gt;

&lt;p&gt;Based on &lt;a href=&#34;http://opendatastructures.org&#34;&gt;Open Data Structures&lt;/a&gt; [Mor], we
maintain the invariant stated above (neither stack falls below 3x the size of
the other). Before giving the implementation let us discuss the running
time. Clearly if we are going to carry out some sequence of operations on
stacks, adding and/or removing some multiple of N, then we are going to be left
with running time of O(N). This would be disastrous since we call &lt;code&gt;balance()&lt;/code&gt; on
each &lt;em&gt;enqueue/dequeue&lt;/em&gt; operation. It turns out though, that while the worst case running
time is O(N), the amortized running time is O(1). Stated another way, for M
enqueue/dequeue operations we will have running time in the order of O(M).&lt;/p&gt;

&lt;p&gt;For those familiar with the running time complexity analysis of dynamic
arrays, the above statement will not come as a surprise. For a more complete
analysis see [Mor].&lt;/p&gt;

&lt;p&gt;One method of balancing the stacks is by way of a couple of additional temporary
stacks and a sequence of &lt;em&gt;push&lt;/em&gt; and &lt;em&gt;pop&lt;/em&gt; operations.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// rebalance stacks
func (d *Deque) rebalance() {
	small, big := order(&amp;amp;d.front, &amp;amp;d.back)
	half := (small.len() + big.len()) / 2
	tmpB := &amp;amp;stack{}
	tmpS := &amp;amp;stack{}
	mvN(tmpB, big, half) // store half of big
	mvAll(tmpS, small)   // store small
	mvAll(small, big)    // put bottom half of big onto small
	mvAll(small, tmpS)   // restore small
	mvAll(big, tmpB)     // restore big
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned previously, &lt;code&gt;order()&lt;/code&gt; simply gives us the stacks back in order of size, the other helper
functions are;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// mvN: move n items from dst and push to src
func mvN(dst, src *stack, n int) {
	for i := 0; i &amp;lt; n; i++ {
		x, _ := src.pop()
		dst.push(x)
	}
}

// mvAll: move all items from src to dst
func mvAll(dst, src *stack) {
	mvN(dst, src, src.len())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See Github for complete
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/deques/twinStacks&#34;&gt;source code&lt;/a&gt; and tests.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Binary Search Tree in Golang</title>
      <link>/blog/bst/</link>
      <pubDate>Tue, 01 Nov 2016 11:37:27 +1100</pubDate>
      
      <guid>/blog/bst/</guid>
      <description>&lt;p&gt;A binary search tree (BST) is a binary tree where each node has a comparable key. As with
any tree, nodes may optionally contain satellite data.&lt;/p&gt;

&lt;p&gt;A BST can support many dynamic container operations, including search, minimum,
maximum, predecessor, successor, insert and delete. The defining feature of a
BST is that keys are maintained in an ordered fashion. This makes a BST a useful
data structure for implementing such things as ordered sets and bags.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;BST time complexity at worst case is O(&lt;em&gt;n&lt;/em&gt;), this occurs when the tree
is a linear chain of &lt;em&gt;n&lt;/em&gt; nodes. The expected height of a randomly built binary
tree is however &lt;em&gt;log n&lt;/em&gt;. This leads to the primary attraction of the BST, namely
that many operations have running time complexity of O(&lt;em&gt;log n&lt;/em&gt;). However, it is worth
keeping in mind the conditions that lead to worst case performance of a binary
tree. Building a tree from a sorted list of keys will produce worst case performance.&lt;/p&gt;

&lt;p&gt;The typical data structure used to implement a binary search tree found in the
literature as pseudo-code is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Node {
    integer key
    left Node
    right Node
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Translated into Go, with the addition of a parent node pointer to facilitate
more complex functionality, this becomes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Node struct {
    key    int
    left   *Node
    right  *Node
    parent *Node
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In beginning our discussion on binary search trees we will ignore satellite
data. This is justified by the fact that a BST with an integer key alone is
useful for many operations coupled with the fact that the addition of satellite
data involves only minor changes the underlying types.&lt;/p&gt;

&lt;p&gt;If one proceeds, using the above node type, to implement typical BST operations,
it will not be long before a subtle problem arises. If one attempts to create an
empty tree by starting with a zero value node &lt;code&gt;var n Node&lt;/code&gt; the tree will contain
a node with the key value of &lt;code&gt;0&lt;/code&gt;. This is because the zero value of a node is
equivalent to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var n Node
    n.key = 0
    n.left = nil
    n.right = nil
    n.parent = nil
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This may not be the desired behaviour. One solution presents itself from
this (overly explicit) snippet. An empty tree can be created using a node pointer instead
of a node &lt;code&gt;var n *Node&lt;/code&gt;. Another solution, and the one we will use henceforth,
is to wrap a pointer to the root node within another data structure&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Tree struct {
    root *Node
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This allows for the zero value of a Tree to be useful &lt;code&gt;var t Tree&lt;/code&gt;. It also
abstracts the details of an empty tree away from the user.&lt;/p&gt;

&lt;h2 id=&#34;tree-traversal&#34;&gt;Tree Traversal&lt;/h2&gt;

&lt;p&gt;It is common to visit the nodes of a binary tree in one of three manners,
pre-order, in-order, or post-order. As the names suggest, these involve visiting
the node before, between, or after visiting it&amp;rsquo;s children. For a BST with
integer keys, it is often most useful to utilise in-order tree traversal (tree
walk). Such a tree traversal will give the keys in ascending sorted order.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Walk tree in order calling fn for each node
func (n *Node) inorder(fn func(n *Node)) {
	if n != nil {
		n.left.inorder(fn)
		fn(n)
		n.right.inorder(fn)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using this function, and Go&amp;rsquo;s support for closures, we can do things like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Flatten: return inorder slice of keys
func (t *Tree) Flatten() []int {
	var keys []int
	fn := func(n *Node) {
		keys = append(keys, n.key)
	}
	t.root.inorder(fn)
	return keys
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Related to tree traversal are the operations minimum and maximum. By the formal
definition for the relation between the keys of a BST&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The keys in a binary search tree are always sorted. Let x be a node in a binary
search tree. If y is a node in the left subtree of x, then y.key &amp;lt; x.key. If y
is a node in the right subtree of x, then y.key &amp;gt;= x.key&lt;/em&gt; [Cor09]&lt;/p&gt;

&lt;p&gt;the node with the maximum key value will be found in the right-most leaf of the
tree&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Max: return maximum key from tree
func (t *Tree) Max() (int, error) {
	if t.root == nil {
		return 0, fmt.Errorf(&amp;quot;Max() called on empty tree&amp;quot;)
	}
	n := t.root.max()
	return n.key, nil
}

// max: find node with maximum key from tree rooted at n
func (n *Node) max() *Node {
	for n.right != nil {
		n = n.right
	}
	return n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This shows one implication of using a separate Tree type. Methods may be
defined on Node types and/or on Tree types. For consistency Node methods will
return a node pointer giving us access to the node while Tree methods will
return the key value. Your millage may vary depending on the specific usage of
the tree. Minimum can be implemented in a similar fashion, for brevity it is
omitted but full source code can be found
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/trees/bsts/intKey/unique&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;insertion-and-deletion&#34;&gt;Insertion and Deletion&lt;/h2&gt;

&lt;p&gt;This section follows the algorithmic design outlined in &lt;em&gt;Introduction to
Algorithms&lt;/em&gt; [Cor09]&lt;/p&gt;

&lt;p&gt;Insertion into a BST is simply a matter of locating the correct position and
inserting a new node. First we will create a new node with the requisite key&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// newNode: create a new node from key
func newNode(key int) *Node {
	var n Node
	n.key = key
	return &amp;amp;n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can insert the node into the tree&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Add key to tree
func (t *Tree) Add(key int) {
	n := newNode(key)
	t.insert(n)
}

// insert node n into t
func (t *Tree) insert(new *Node) {
	if t.root == nil {
		t.root = new
		return
	}
	// find position
	var p *Node = nil
	n := t.root
	for n != nil {
	    p = n
	    if new.key &amp;lt; n.key {
		    n = n.left
	    } else {
		    n = n.right
	    }
	}
	// insert node
	if new.key &amp;lt; p.key {
		p.left = new
	} else {
		p.right = new
	}
	new.parent = p
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus far we have allowed multiple keys with the same value, this may or may not
be the required behaviour. It is however, trivial to transform one implementation to
the other, requiring only the addition of a check for equality between the new
nodes key and the current key&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    // ...
    for n != nil {
		p = n
		if new.key == n.key {
			return
		} else if new.key &amp;lt; n.key {
			n = n.left
		} else {
			n = n.right
		}
	}
    // ...

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Detion is somewhat more involved. One way to think about it is as
follows; if a node has no children it can safely be removed. If a node has only
children in one subtree it can be replaced by that subtree. If a node has two
children it&amp;rsquo;s successor must be found and used to replace the deleted node. Only
the last of these three cases presents any complexity. Firstly, let us get the
successor node to a key value that exists within the tree&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Successor: find smallest key value larger than key
// panic if key not present, ok if found
func (t *Tree) Successor(key int) (int, bool) {
	n := t.root.find(key)
	if n == nil {
		panic(&amp;quot;Succesor() called with non-existant key&amp;quot;)
	}
	next := n.successor()
	if next == nil {
		return 0, false
	}
	return next.key, true
}

// find node by key
func (n *Node) find(key int) *Node {
	for n != nil &amp;amp;&amp;amp; key != n.key {
		if key &amp;lt; n.key {
			n = n.left
		} else {
			n = n.right
		}
	}
	return n
}

// successor: return node with smallest key larger than n.key
func (n *Node) successor() *Node {
	if n.right != nil {
		return n.right.min()
	}
	p := n.parent
	for p != nil &amp;amp;&amp;amp; n == p.right {
		n = p
		p = p.parent
	}
	return p
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now returning to deletion. As stated it is not overly complex to remove a node
with zero or one child(ren). Let us now focus on the case of a node (n) with two
children.&lt;/p&gt;

&lt;p&gt;This can be split into two cases; firstly if the successor (s) of n is the
direct right child of n (this implies s has a nil left child) then s can be
&amp;lsquo;transplanted&amp;rsquo; into the position of n.&lt;/p&gt;

&lt;p&gt;If the successor is further down the right subtree of n then it must be further
moved. We can modify the right right subtree of n by removing s and creating a
tree with s as the root and the reaming nodes as the right child of s. Since the
successor is by definition the smallest of n&amp;rsquo;s right children this new tree
maintains correct structure. This tree can then be transplanted into position.&lt;/p&gt;

&lt;p&gt;The code to transplant a node is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// transplant replaces subtree rooted at u with subtree rooted at v
func (t *Tree) transplant(u, v *Node) {
	if u.parent == nil {
		t.root = v
	} else if u == u.parent.left {
		u.parent.left = v
	} else {
		u.parent.right = v
	}
	if v != nil {
		v.parent = u.parent
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then wrap the call to Delete (by key) method around a call to delete (by Node),
easing later additions to the Tree type.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Delete node with key from tree
// true if deleted
func (t *Tree) Delete(key int) bool {
	n := t.root.find(key)
	if n == nil {
		return false
	}
	t.delete(n)
	return true
}

func (t *Tree) delete(d *Node) {
	if d.left == nil {
		t.transplant(d, d.right)
	} else if d.right == nil {
		t.transplant(d, d.left)
	} else {
		n := d.right.min()
		if n.parent != d {
			t.transplant(n, n.right)
			n.right = d.right
			n.right.parent = n
		}
		t.transplant(d, n)
		n.left = d.left
		n.left.parent = n
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Often when thinking about algoritms involving binary trees, recursive solutions
come to mind. And while many binary tree operations can be implemented in a
recursive manner some can be re-written in an iterative manner. Some however
cannot (e.g in-order tree walk). We must be careful to understand the
implications of calling recursive functions in a language that does not
implement tail call optimization. It is therefore sometimes prudent to consider an
iterative implementation as well as recursive. Here is one such function&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// elem: true if node with key exists in tree rooted at node n, recursive version
func (n *Node) elem(key int) bool {
	if n == nil {
		return false
	}
	if key == n.key {
		return true
	} else if key &amp;lt; n.key {
		return n.left.elem(key)
	}
	return n.right.elem(key)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And an iterative implementation&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// elem: true if node with key exists in tree rooted at node n, iterative version
func (n *Node) elem(key int) bool {
	found := false
	for {
		if n == nil {
			break // found = false
		}
		if n.key == key {
			found = true
			break
		}
		if key &amp;lt; n.key {
			n = n.left
		} else {
			n = n.right
		}
	}
	return found
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For full source code including additional operations (sum, size, height etc) see
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/trees/bsts/intKey/unique&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a final note, binary search trees can take many forms. If you have any
ideas on how I can better make use of search trees, or any comments at all,
please feel free to email me or submit a pull request.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[Cor09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H. Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bag Data Structure in Golang</title>
      <link>/blog/bag/</link>
      <pubDate>Wed, 26 Oct 2016 10:49:04 +1100</pubDate>
      
      <guid>/blog/bag/</guid>
      <description>&lt;p&gt;A bag is a container of non-unique items. Bags are defined by the following
operations &lt;em&gt;Length&lt;/em&gt;, &lt;em&gt;Add&lt;/em&gt;, &lt;em&gt;Delete&lt;/em&gt; and &lt;em&gt;Find&lt;/em&gt;. Bags often also need to support
&lt;em&gt;FindAll&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Bags can be ordered or un-ordered. This post will be discussing un-ordered
bags.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Bags are useful when one needs to store a bunch of things and later check
if a certain thing is present. For example, storing the characters of a string
(and perhaps, the frequency count).&lt;/p&gt;

&lt;p&gt;A bag can be easily implemented in Go using a map.&lt;/p&gt;

&lt;h2 id=&#34;bag-of-integers&#34;&gt;bag of integers&lt;/h2&gt;

&lt;p&gt;For the sake of simplicity, we will first cover a bag of integers, then move
onto a bag of characters (including some useful functions on such a bag).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package bag

type count int

type Bag map[int]count

func (b *Bag) Len() int {
	sum := 0
	for _, v := range *b {
		sum += int(v)
	}
	return sum
}

func (b *Bag) Add(x int) {
	(*b)[x]++
}

func (b *Bag) Delete(x int) {
	_, ok := (*b)[x]
	if ok {
		(*b)[x]--
	}
}

func (b *Bag) Find(x int) (int, bool) {
	count, ok := (*b)[x]
	return int(count), ok
}

func (b *Bag) FindAll(x int) (int, bool) {
	return b.Find(x) // not useful for this implementation
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then use our bag of integers like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func fn() {
    bag := make(Bag)

	// add some values to bag
	for i := 0; i &amp;lt; 5; i++ {
		bag.Add(i)
    }

    // check if we have a &#39;2&#39;
    x, ok := bag.Find(2)  // x = 1 (one &#39;2&#39; in bag), ok = true

    // check if we have a &#39;10&#39;
    x, ok = bag.Find(10)  // ok = false (no &#39;10&#39; in bag)

    // add a second &#39;2&#39; and check we now have two of them in bag 
    bag.Add(2)
    x, ok := bag.Find(2)  // x = 2 (two 2&#39;s in bag), ok = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bag-of-bytes&#34;&gt;bag of bytes&lt;/h2&gt;

&lt;p&gt;A bag of bytes can be used to store such things as byte values for characters
encoded using ASCII. This bag would not be very useful for storing text written
in Greek but would be useful for some cryptography tasks.&lt;/p&gt;

&lt;p&gt;The basic operations are similar to the above, except of course we replace
occurences of &lt;code&gt;int&lt;/code&gt; with &lt;code&gt;byte&lt;/code&gt;. Also we add a helper function to create a bag
from a string (ASCII values only remember).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Bag map[byte]int

func makeBag(s string) Bag {
	bag := make(Bag)
	for i := 0; i &amp;lt; len(s); i++ {
		bag.Add(s[i])
	}
	return bag
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then write some other functions to operate on this bag&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Bag) difference(c Bag) Bag {
	bag := make(Bag)
	for k, vb := range *b {
		vc, ok := c[k]
		if ok {
			if vb &amp;gt; vc {
				bag[k] = vb - vc
			}
		} else {
			bag[k] = vb
		}
	}
	return bag
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, one can implement union, and intersection in the above manner. See
Github for complete
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/bags&#34;&gt;source code&lt;/a&gt; and tests.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[Cor09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H. Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Queue Data Structure in Golang</title>
      <link>/blog/queue/</link>
      <pubDate>Wed, 26 Oct 2016 09:54:21 +1100</pubDate>
      
      <guid>/blog/queue/</guid>
      <description>&lt;p&gt;A queue is a container that supports retrieval by first-in, first-out (FIFO)
order. The &lt;em&gt;get&lt;/em&gt; and &lt;em&gt;put&lt;/em&gt; operations for a queue are usually called &lt;em&gt;enqueue&lt;/em&gt; and
&lt;em&gt;dequeue&lt;/em&gt;, other operations may include &lt;em&gt;isEmpty&lt;/em&gt;. A full description of
queues can be found online &lt;a href=&#34;http://opendatastructures.org&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Queue&amp;rsquo;s minimise the maximum time spent waiting, however the average wait time
will be the same whether a LIFO or a FIFO is used.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;A queue can be easily implemented in Go using slices.&lt;/p&gt;

&lt;h2 id=&#34;queue-of-integers&#34;&gt;queue of integers&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;package queue

type Queue []int

func (q *Queue) Enqueue(x int) {
	*q = append(*q, x)
}

func (q *Queue) Dequeue() (int, bool) {
	if q.isEmpty() {
		return 0, false
	}

	x := (*q)[0]
	*q = (*q)[1:]
	return x, true
}

func (q *Queue) isEmpty() bool {
	return len(*q) == 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then use our queue of integers like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func fn() {
    var q Queue

    q.Enque(1)
    q.Enque(2)
    q.Enque(3)

    x := q.Dequeue()  // x = 1
    x = q.Dequeue()   // x = 2
    x = q.Dequeue()   // x = 3
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[Cor09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H. Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Stack Data Structure in Golang</title>
      <link>/blog/stack/</link>
      <pubDate>Mon, 17 Oct 2016 08:28:17 +1100</pubDate>
      
      <guid>/blog/stack/</guid>
      <description>&lt;p&gt;A stack is a container that supports retrieval by last-in, first-out (LIFO)
order. The &lt;em&gt;get&lt;/em&gt; and &lt;em&gt;put&lt;/em&gt; operations for stacks are usually called &lt;em&gt;push&lt;/em&gt; and
&lt;em&gt;pop&lt;/em&gt;, other operations may include &lt;em&gt;peek&lt;/em&gt; and &lt;em&gt;isEmpty&lt;/em&gt;. A full description of
stacks can be found online &lt;a href=&#34;http://opendatastructures.org&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stacks are simple to implement and very efficient. For this reason, stacks are
probably the right container to use when retrieval order doesn&amp;rsquo;t matter [Ski08]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A stack can be easily implemented in Go using slices.&lt;/p&gt;

&lt;h2 id=&#34;stack-of-integers&#34;&gt;stack of integers&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// stack of integers
package stack

type Stack []int

// IsEmpty: check if stack is empty
func (s *Stack) IsEmpty() bool {
	return len(*s) == 0
}

// Push a new integer onto the stack
func (s *Stack) Push(x int) {
	*s = append(*s, x)
}

// Pop: remove and return top element of stack, return false if stack is empty
func (s *Stack) Pop() (int, bool) {
	if s.IsEmpty() {
		return 0, false
	}

	i := len(*s) - 1
	x := (*s)[i]
	*s = (*s)[:i]

	return x, true
}

// Peek: return top element of stack, return false if stack is empty
func (s *Stack) Peek() (int, bool) {
	if s.IsEmpty() {
		return 0, false
	}

	i := len(*s) - 1
	x := (*s)[i]

	return x, true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then use our stack of integers like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func fn() {
    var stack Stack

    stack.Push(1)
    stack.Push(2)
    stack.Push(3)

    x := stack.Peek()  // x = 3
    x = stack.Pop()    // x = 3
    x = stack.Peek()   // x = 2
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is trivial to replace integers with any other type
(&lt;a href=&#34;https://github.com/tcharding/types/tree/master/stacks/string&#34;&gt;string&lt;/a&gt;,
struct, etc).&lt;/p&gt;

&lt;h2 id=&#34;stack-of-anything&#34;&gt;stack of anything&lt;/h2&gt;

&lt;p&gt;One downside to the above method is that a new stack needs to be written for
each data type. An alternative is to use the empty interface to allow stacks of
anything.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// All types satisfy the empty interface, so we can store anything here.
type Stack []interface{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then any time we pop or peek at an item from the stack we use a type
assertion.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var stack Stack
stack.Push(&amp;quot;this&amp;quot;)

item := stack.Pop()
fmt.Printf(&amp;quot;%s\n&amp;quot;, item.(string))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This comes with the usual warnings that using the empty type interface reduces
the ability of the compiler to catch type errors, one of the benefits of using a
strongly typed language.&lt;/p&gt;

&lt;p&gt;Full source code is available &lt;a href=&#34;https://github.com/tcharding/types/tree/master/stacks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also Douglas Hall has done a nice stack implementation using linked lists instead of
slices. You can find his gist &lt;a href=&#34;https://gist.github.com/bemasher/1777766&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[Cor09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H. Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>initial commit</title>
      <link>/blog/initial-commit/</link>
      <pubDate>Tue, 11 Oct 2016 22:10:57 +1100</pubDate>
      
      <guid>/blog/initial-commit/</guid>
      <description>&lt;p&gt;According to &lt;strong&gt;Apprenticeship Patterns&lt;/strong&gt; by Bavid H. Hoover and Adewale Oshineye,
in order to become a journeyman one must learn to explain their craft to
others. This is one apprentices effort to learn these skills.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>