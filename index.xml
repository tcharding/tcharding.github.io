<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tobin Harding</title>
    <link>/index.xml</link>
    <description>Recent content on Tobin Harding</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 17 Dec 2016 21:00:43 +1100</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Resume</title>
      <link>/resume/</link>
      <pubDate>Sat, 17 Dec 2016 21:00:43 +1100</pubDate>
      
      <guid>/resume/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;12 years&lt;/strong&gt; experience using &lt;strong&gt;Linux&lt;/strong&gt;. Contributed to various open source projects. &lt;strong&gt;18 months&lt;/strong&gt; full time programming (&lt;strong&gt;self study&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;97th percentile&lt;/strong&gt; in algorithms on &lt;a href=&#34;https://www.hackerrank.com/tcharding&#34;&gt;HackerRank&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Undergraduate&lt;/strong&gt; and &lt;strong&gt;postgraduate&lt;/strong&gt; degrees  in computer science.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Founder&lt;/strong&gt; of Central Coast Linux Users Group (LUG).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;code-written-in-the-last-12-months&#34;&gt;Code Written in the last 12 months&lt;/h2&gt;

&lt;p&gt;All code is open source and hosted on &lt;a href=&#34;https://github.com/tcharding/self_learning&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;golang&#34;&gt;Golang&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;140+ algorithmic problems on &lt;a href=&#34;https://www.hackerrank.com/tcharding&#34;&gt;HackerRank&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Data structures. Implementations and &lt;a href=&#34;http://tobin.cc/blog/&#34;&gt;blog&lt;/a&gt; posts.&lt;/li&gt;
&lt;li&gt;Exercises from The Go Programming Language.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;haskell&#34;&gt;Haskell&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;50+ problems from &lt;a href=&#34;https://wiki.haskell.org/H-99:_Ninety-Nine_Haskell_Problems&#34;&gt;Ninety-Nine Haskell Problems&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Approximately 20 problems from &lt;a href=&#34;https://projecteuler.net/&#34;&gt;Project Euler&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;scheme&#34;&gt;Scheme&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Guile patch modifying compiler output (in C and Scheme).&lt;/li&gt;
&lt;li&gt;Worked all Exercises from SICP (upto exercise 4.71).&lt;/li&gt;
&lt;li&gt;Exercises from The Scheme Programming Language.&lt;/li&gt;
&lt;li&gt;Worked The Little Schemer.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;armv4t&#34;&gt;ARMv4T&lt;/h3&gt;

&lt;p&gt;Toolchain: gcc and the GNU Assembler.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Exercises from ARM Assembly Language.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;linux-kernel&#34;&gt;Linux Kernel&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Updated &lt;a href=&#34;https://github.com/tcharding/ldd3-examples-4.6&#34;&gt;source code&lt;/a&gt; from &lt;a href=&#34;https://lwn.net/Kernel/LDD3/&#34;&gt;ldd3&lt;/a&gt; to kernel version 4.6.0.&lt;/li&gt;
&lt;li&gt;A few trivial Kernel patches into &lt;a href=&#34;http://git.kernel.org/cgit/linux/kernel/git/gregkh/staging.git/log/?qt=grep&amp;amp;q=Tobin+C+Harding&#34;&gt;GregKH staging&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Initial challenges from &lt;a href=&#34;http://eudyptula-challenge.org/&#34;&gt;The Eudyptula Challenge&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;python&#34;&gt;Python&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Contributed to the &lt;a href=&#34;https://github.com/OpenBazaar/OpenBazaar-Server&#34;&gt;Open Bazaar&lt;/a&gt; project.&lt;/li&gt;
&lt;li&gt;Completed first four sets from the &lt;a href=&#34;https://cryptopals.com/&#34;&gt;Matasano Cryptography Challenges&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;30+ problems from &lt;a href=&#34;https://projecteuler.net/&#34;&gt;Project Euler&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;c&#34;&gt;C&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;All exercise upto chapter 47 of The Linux Programming Interface&lt;/li&gt;
&lt;li&gt;All exercises from UNIX Network Programming.&lt;/li&gt;
&lt;li&gt;All exercises from Advanced Programming in the UNIX Environment.&lt;/li&gt;
&lt;li&gt;Majority of exercises from UNIX Systems Programming.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;education&#34;&gt;Education&lt;/h2&gt;

&lt;h3 id=&#34;self-learning&#34;&gt;Self Learning&lt;/h3&gt;

&lt;p&gt;For the last 18 months I have worked assiduously on becoming a comptent
programmer. I have &lt;a href=&#34;https://github.com/tcharding/work-logs&#34;&gt;logged&lt;/a&gt; hours and topics worked. Topic outline for the last 12
months can be seen above. During this time I have studied numerous texts on
topics related to software development. See &lt;a href=&#34;http://tobin.cc/reading-list&#34;&gt;~/books&lt;/a&gt;
for full listing, highlights include;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Structure and Interpretation of Computer Programs&lt;/strong&gt; Harold Abelson, Gerald Jay Sussman, Julie Sussman&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Art of Computer Programming&lt;/strong&gt; (volumes 1 and 2) Donald E. Knuth&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Applied Cryptography&lt;/strong&gt; Bruce Schneier&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clean Code, A Handbook of Agile Software Craftsmanship&lt;/strong&gt; Robert C. Martin&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;UNIX Network Programming&lt;/strong&gt; W. Richard Stevens, Bill Fenner, Andrew M. Rudoff&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Advanced Programming in the UNIX Environment&lt;/strong&gt; W. Richard Stevens, Stephen A. Rag&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;graduate-diploma-in-computer-science&#34;&gt;Graduate Diploma in Computer Science&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Pass with High Distinction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;University of New England, Australia (completed 2014).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Parallel and Distributed Computing.&lt;/li&gt;
&lt;li&gt;Computer Architecture and Assembler.&lt;/li&gt;
&lt;li&gt;C++ Programming.&lt;/li&gt;
&lt;li&gt;Programming Languages for Artificial Intelligence.&lt;/li&gt;
&lt;li&gt;Web and Internet Programming.&lt;/li&gt;
&lt;li&gt;Information Technology Project (patient management application written in Objective C).&lt;/li&gt;
&lt;li&gt;Graduate Diploma in Computer Science Project (UNIX shell written in C).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;bachelor-of-science&#34;&gt;Bachelor of Science&lt;/h3&gt;

&lt;p&gt;University of Sydney, Australia (completed 2008).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Awarded Bachelor of Science majoring in computer science.&lt;/li&gt;
&lt;li&gt;Completed double major, software development and computer networking.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>HackerRank: First milestone reached.</title>
      <link>/blog/hackerrank1/</link>
      <pubDate>Tue, 06 Dec 2016 11:14:39 +1100</pubDate>
      
      <guid>/blog/hackerrank1/</guid>
      <description>&lt;p&gt;&lt;em&gt;To appreciate programming as an intellectual activity in its own right &amp;hellip; you
must read and write computer programs - many of them.&lt;/em&gt;[ASS96]&lt;/p&gt;

&lt;p&gt;For the past nine weeks I have been working on programming questions at
&lt;a href=&#34;http://hackerrank.com&#34;&gt;HackerRank&lt;/a&gt; completing questions in the &amp;lsquo;practice area&amp;rsquo; i.e I have
not competed in any competitive programming competitions offered by the
site. Today I reached the first milestone I had set, namely, to get a top 1000
ranking (96th percentile) in the algorithms sub domain.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;hackerrank-com&#34;&gt;HackerRank.com&lt;/h3&gt;

&lt;p&gt;First a brief introduction to HackerRank (1). The site is one of many
competitive programming sites available currently. This is not, in any way, a
post about the merits of one site vs another. As such I do not intend to compare
HackerRank to any of its competitors.&lt;/p&gt;

&lt;p&gt;HackerRank is divided into two areas. One is the competitive programming
competitions and the other is the practice arena, an area of the site listing
multiple discrete programming questions divided into domains. This post is
concerning the practice arena. I will not be mentioning the competitions again
and may at times take the liberty of referring to the practice arena as &amp;lsquo;the
site&amp;rsquo; in general without further specification.&lt;/p&gt;

&lt;p&gt;The site (I did warn you), is divided into domains. The three &amp;lsquo;big&amp;rsquo; ones are
algorithms, artificial intelligence, and functional programming. Each domain is
separate in terms of score and rank. For each domain a user will have score (of
points for completed questions) and a rank (of all users of that domain). Each
domain is also divided into sub domains, such as sorting, graph theory
etc. Questions are rated easy, medium, hard etc and allotted a maximum
score. Partial solutions garner partial scores and multiple submissions are of
course allowed. Also statistics on success rates of completion are listed for
each question.&lt;/p&gt;

&lt;h3 id=&#34;statistics&#34;&gt;Statistics&lt;/h3&gt;

&lt;p&gt;I focused on the algorithms domain. I used Golang for all questions. As stated
above my first milestone was to get into the top 1000. During the nine weeks it
took me to do this I was aided by the texts listed in the bibliography
below. The primary aim of completing this milestone was to become a better
programmer and more specifically to become a better programmer in Go.&lt;/p&gt;

&lt;p&gt;Without further ado;&lt;/p&gt;

&lt;p&gt;150 hours over nine weeks&lt;br /&gt;
140 questions attempted&lt;br /&gt;
12 000 lines of code&lt;/p&gt;

&lt;h3 id=&#34;what-i-learned&#34;&gt;What I learned&lt;/h3&gt;

&lt;p&gt;All solutions must be complete i.e no libraries, so data structures and algorithms must be
written from scratch. This means that I learned thoroughly, for example, how to
implement and traverse a graph.&lt;/p&gt;

&lt;p&gt;The importance of data structures quickly becomes very clear, most used were; queue, stack, tree
(binary search tree, ordered statistical tree, n-ary tree), graph
(directed/undirected, weighted/unweighted).&lt;/p&gt;

&lt;p&gt;All questions read input from standard in and expect output on standard out. For
simplicity I tended to use &lt;code&gt;fmt.Fscanf&lt;/code&gt;. However on occasion IO
was found to be a bottleneck and I learned that &lt;code&gt;bufio.Scanner&lt;/code&gt; is faster.&lt;/p&gt;

&lt;p&gt;To test each solution I used a trick from Donovan and Kernighan [DK16]. In the
main file we declare two global variables &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt;. Also &lt;code&gt;main()&lt;/code&gt; is
simply a call to another function;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var (
	in  io.Reader = os.Stdin
	out io.Writer = os.Stdout
)

func main() {
	solve()
}

func solve() {
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then in the test file, using &lt;a href=&#34;https://dave.cheney.net/2013/06/09/writing-table-driven-tests-in-go&#34;&gt;table driven testing&lt;/a&gt;, we override &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; in
order to supply test cases and check the output.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func Tes(t *testing.T) {
	var tests = []struct {
		input string
		want  string
	}{
	        {&amp;quot;1 2 3\n&amp;quot;, &amp;quot;10\n&amp;quot;},
    		{&amp;quot;5 6 7\n&amp;quot;, &amp;quot;11\n&amp;quot;},
	}

	for _, test := range tests {
		out = new(bytes.Buffer)
		in = bytes.NewBufferString(test.input)
		solve()

		if got := out.(*bytes.Buffer).String(); got != test.want {
			t.Errorf(&amp;quot;input: %s\n got: %s\n want: %s\n&amp;quot;,
				test.input, got, test.want)
		}
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generally speaking the easy questions are solvable with an O(N^2) algorithm. Once
onto the medium questions however typically an O(NlogN) solution is
required. Often it suffices to look over the solution and change the algorithm
as needed but at times bench marking is helpful. I learned that Go&amp;rsquo;s built in
benchmark facilities are quick and easy to use and provided all one needs to get
the running times down on trickier questions.&lt;/p&gt;

&lt;p&gt;Bench marking can be implemented (assuming the question is coded as above) in
Golang by simply adding to a test file the following function;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func BenchmarkSolve(b *testing.B) {
	for i := 0; i &amp;lt; b.N; i++ {
		input := &amp;quot;1 2 3\n&amp;quot;
		out = new(bytes.Buffer)
		in = bytes.NewBufferString(input)
		solve()
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A Bench mark file can be produced with &lt;code&gt;$ go test -run=None -bench=Solve
-cpuprofile=cpu.out&lt;/code&gt;. One can then view the output using &lt;code&gt;go tool pprof -text
-nodecount=20 ./prog.test cpu.out&lt;/code&gt;. Where &lt;code&gt;prog.test&lt;/code&gt; is the executable that &lt;code&gt;go
test&lt;/code&gt; saves by default using the program name and the suffix &lt;code&gt;.test&lt;/code&gt;. The
&lt;code&gt;-run=None&lt;/code&gt; flag stops all other tests from being run during the bench mark.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I found HackerRank to be well written, both the content and the site
operations. The questions were well paced and progressed in difficulty at a nice rate. There
are ample questions and a nice little dopamine release generated
by each score increase to keep you coming back. A text book or two on data
structures and algorithms is surely advisable. I found Golang to be very
suitable and pleasant to work with even though it can be verbose at times. If
you would like to deepen your understanding and quicken your algorithmic output
I can wholeheartedly recommend a few weeks spent on HackerRank.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;notes&#34;&gt;Notes:&lt;/h4&gt;

&lt;p&gt;(1) &lt;strong&gt;I am not affiliated in any way with hackerrank.com&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[CLRS09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H.Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;br /&gt;
[ASS96] - &lt;strong&gt;Structure and Interpretation of Computer Programs&lt;/strong&gt;, Harold Abelson
andGerald Jay Sussman with Julie Sussman.&lt;br /&gt;
[DK16] - &lt;strong&gt;The GO Programming Language&lt;/strong&gt;, Alan A. A. Donovan, Brian
W. Kernighan.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Heap Data Structure in Golang</title>
      <link>/blog/heap/</link>
      <pubDate>Thu, 10 Nov 2016 08:29:33 +1100</pubDate>
      
      <guid>/blog/heap/</guid>
      <description>&lt;p&gt;A heap is a data structure that supports the operations &lt;em&gt;insert&lt;/em&gt; and
&lt;em&gt;extract&lt;/em&gt;. Heaps typically come in two varieties, &lt;em&gt;min heap&lt;/em&gt; (for extracting the
minimum value) and &lt;em&gt;max heap&lt;/em&gt;. A heap is built using a binary tree where each
node is said to &lt;em&gt;dominate&lt;/em&gt; the nodes below it. The meaning of dominate depends
on the type of heap being implemented, for a &lt;em&gt;min heap&lt;/em&gt; the key of each node is
&lt;em&gt;less&lt;/em&gt; than the keys of both of child nodes.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;From here on, without loss of generality, we will talk about a heap of integers
(keys) ignoring satellite data that may or may not be associated with each
integer key. &lt;em&gt;Node&lt;/em&gt; and &lt;em&gt;key&lt;/em&gt; will therefore be used interchangeably.&lt;/p&gt;

&lt;p&gt;Like a binary search tree a heap can be implemented using a linked data
structure. There is however, a nifty method of implementing a heap using an
array, thereby reducing the memory requirements since there are no pointers to
store. We store the data as an array of keys and use the index of the keys to
implicitly satisfy the role of pointers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The root node is stored at index 1 and all operations are 1-indexed&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For node at index &lt;em&gt;k&lt;/em&gt; the left child can be found at index &lt;em&gt;2k&lt;/em&gt; and the
right child at index &lt;em&gt;2k + 1&lt;/em&gt;. (Quite clearly, checks must be made prior to
access that an index lies within the underlying array).&lt;/p&gt;

&lt;p&gt;One additional limitation must be placed on the tree, that it is &lt;em&gt;complete&lt;/em&gt;, i.e
all levels of the tree are full with the possible exception of the last level,
and if the last level is not full all nodes are as far to the left as
possible. This limitation results in an array with no holes in it.&lt;/p&gt;

&lt;p&gt;A heap as just described may be defined in Go as such;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type heap struct {
	xs []int
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We wrap the array inside a struct to abstract the implementation and limit
access to the functions that we define. Care must be taken
to remember that the heap is 1-indexed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h *heap) Len() int {
	return len(h.xs) - 1 // heap is 1-indexed
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Insertion of a key into a heap can be achieved by adding the key to the end of
the underlying array. Whilst maintaining the structure of the heap this may
violate the &lt;em&gt;heap property&lt;/em&gt; of the parent of the newly inserted key, namely the
parent of the newly inserted key may not be dominant. The heap property for the
parent node can be restored by swapping the newly inserted child node with the
parent. This may in turn, result in the parent above violating the heap
property. We can continue this &lt;em&gt;bubbling&lt;/em&gt; of a node to successively higher nodes
until the heap property is restored. When swapping a node with the parent node
we need not consider the sibling node since if a node dominates the parent then
by definition it dominates the other sibling also.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Insert x into the heap
func (h *heap) Insert(x int) {
	(*h).xs = append(h.xs, x)
	h.bubbleUp(len(h.xs) - 1)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that parenthesis are required to dereference the heap pointer in order to save the
return value of &lt;code&gt;append()&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (h *heap) bubbleUp(k int) {
	p, ok := parent(k)
	if !ok {
		return // k is root node
	}
	if h.xs[p] &amp;gt; h.xs[k] {
		h.xs[k], h.xs[p] = h.xs[p], h.xs[k]
		h.bubbleUp(p)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The function terminates when either the node is in place or it has reached the
root position.&lt;/p&gt;

&lt;p&gt;We define functions for manipulating indices as described above;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// get index of parent of node at index k
func parent(k int) (int, bool) {
	if k == 1 {
		return 0, false
	}
	return k / 2, true
}

// get index of left child of node at index k
func left(k int) int {
	return 2 * k
}

// get index of right child of node at index k
func right(k int) int {
	return 2*k + 1
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are now ready to extract the key for which our heap was designed (minimum
or maximum). This key is clearly at index 1, extracting this key however, leaves a hole which
must be filled. Swapping the last key of the array into the hole restores the
heap structure but once again may violate the &lt;em&gt;heap property&lt;/em&gt;. In a similar
fashion to insertion we can restore the heap property by bubbling this node down
the tree until it is either a leaf node or no longer violates the heap
property. In doing this we must consider both child nodes and swap any
non-dominant parent node with the child node that is &lt;em&gt;most&lt;/em&gt; dominant in order for
the heap property of these three nodes to be maintained.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// ExtractMin: get minimum value of heap
// and remove value from heap
func (h *heap) ExtractMin() (int, bool) {
	if h.Len() == 0 {
		return 0, false
	}
	v := h.xs[1]
	h.xs[1] = h.xs[h.Len()]
	(*h).xs = h.xs[:h.Len()]
	h.bubbleDown(1)
	return v, true
}
    
func (h *heap) bubbleDown(k int) {
	min := k
	c := left(k)

	// find index of minimum value (k, k&#39;s left child, k&#39;s right child)
	for i := 0; i &amp;lt; 2; i++ {
		if (c + i) &amp;lt;= h.Len() {
			if h.xs[min] &amp;gt; h.xs[c+i] {
				min = c + i
			}
		}
	}
	if min != k {
		h.xs[k], h.xs[min] = h.xs[min], h.xs[k]
		h.bubbleDown(min)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Caution is again needed here since the array indexing and loop conditionals are
unusual because of the 1-indexing.&lt;/p&gt;

&lt;p&gt;See Github for complete
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/heaps/minInt&#34;&gt;source code&lt;/a&gt; and tests.&lt;/p&gt;

&lt;h3 id=&#34;final-note&#34;&gt;Final Note&lt;/h3&gt;

&lt;p&gt;This implementation is based on the text &lt;em&gt;The Algorithm Design
Manual&lt;/em&gt; [Ski08]. In this, the author Steven S. Skiena makes an interesting
observation on the construction of a heap. At first glance one may think to
construct a heap by repeated calls to &lt;code&gt;insert()&lt;/code&gt;. Inserting into a heap (like
any balanced tree) takes O(log &lt;em&gt;n&lt;/em&gt;)), so heap construction in this manner has
worst case running time of O(&lt;em&gt;n&lt;/em&gt; log &lt;em&gt;n&lt;/em&gt;). We can do better, Skiena notes, if we
observe that a &lt;em&gt;full&lt;/em&gt;, &lt;em&gt;complete&lt;/em&gt; tree of &lt;em&gt;n&lt;/em&gt; nodes has &lt;em&gt;n/2&lt;/em&gt; leaf nodes. These
leaf nodes may be considered as sub-trees that maintain the heap property (since
they have only a single node). If then, we base a heap on any array we need only
&lt;em&gt;bubble up&lt;/em&gt; &lt;em&gt;n/2&lt;/em&gt; nodes in order to achieve a heap for which the heap property
holds. This still gives an &lt;em&gt;upper bound&lt;/em&gt; of O(&lt;em&gt;n&lt;/em&gt; log &lt;em&gt;n&lt;/em&gt;), however Skiena goes
on to show that this leads to a &lt;em&gt;not quite geometric&lt;/em&gt; series that he then
assures us quickly converges to linear. He does however, caution us that this
benefit may not be that useful if the algorithm we plan to use our heap for is
not governed by the construction (i.e heapsort will still run in O(&lt;em&gt;n&lt;/em&gt; log
&lt;em&gt;n&lt;/em&gt;)).&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deque Data Structure in Golang</title>
      <link>/blog/deque/</link>
      <pubDate>Tue, 08 Nov 2016 11:14:55 +1100</pubDate>
      
      <guid>/blog/deque/</guid>
      <description>&lt;p&gt;A deque is type of queue which enables adding and removing items from both
ends. Deque ends have such names as &lt;em&gt;left&lt;/em&gt;/&lt;em&gt;right&lt;/em&gt;, &lt;em&gt;front&lt;/em&gt;/&lt;em&gt;rear&lt;/em&gt; or, as we
will use here, &lt;em&gt;front&lt;/em&gt; and &lt;em&gt;back&lt;/em&gt;. The &lt;em&gt;add/remove&lt;/em&gt; operations on a deque are
typically called &lt;em&gt;enqueue&lt;/em&gt; and &lt;em&gt;dequeue&lt;/em&gt;. For ease of explanation but without loss
of generality, we limit discussion to a deque of integers.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;This gives us the following;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Deque struct {
	// Has unexported fields.
}

func (d *Deque) DequeueB() (int, bool)
func (d *Deque) DequeueF() (int, bool)
func (d *Deque) EnqueueB(x int)
func (d *Deque) EnqueueF(x int)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One method of implementing a deque is to use two stacks, one representing the
front of the deque and the other representing the back of the deque. &lt;em&gt;Enqueueing&lt;/em&gt;
and &lt;em&gt;dequeueing&lt;/em&gt; then become simply a matter of &lt;em&gt;pushing&lt;/em&gt; or &lt;em&gt;popping&lt;/em&gt; to, or from, the
appropriate stack. . We will use a simple stack, supporting the operations push, pop, and
length. Previous blog &lt;a href=&#34;../stack&#34;&gt;post&lt;/a&gt; on implementing stacks in Golang.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type stack []int

// push a new integer onto the stack
func (s *stack) push(x int) {
	*s = append(*s, x)
}

// pop: remove and return top element of stack, return false if stack is empty
func (s *stack) pop() (int, bool) {
	if s.len() == 0 {
		return 0, false
	}

	i := len(*s) - 1
	x := (*s)[i]
	*s = (*s)[:i]

	return x, true
}

func (s *stack) len() int {
	return len(*s)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By now, the astute reader will be asking what happens when one stack becomes
empty and a further request comes to deque from that end. The solution to this
dilemma presents the only complexity in this implementation of a deque. Each
time an item is added to, or removed from, the deque we balance the two stacks to
maintain the invariant that while there are 2 or more items, each stack holds at
least one third as many items as the other. In code, that is;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// balance stacks if needed
func (d *Deque) balance() {
	small, big := order(&amp;amp;d.front, &amp;amp;d.back)
	if small.len() == 0 &amp;amp;&amp;amp; big.len() == 1 {
		return
	}
	if 3*d.front.len() &amp;lt; d.back.len() ||
		3*d.back.len() &amp;lt; d.front.len() {
		d.rebalance()
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;order()&lt;/code&gt; simply gives us the stacks back in order of size. Ignoring the
implementation of &lt;code&gt;rebalance()&lt;/code&gt; and time complexity for now, we have a deque that
maintains two &lt;em&gt;&amp;lsquo;balanced&amp;rsquo;&lt;/em&gt; stacks, one holding items for the front of the deque
and the other holding items for the back of the deque. We can enqueue and
dequeue from both ends.&lt;/p&gt;

&lt;h2 id=&#34;balancing-the-deque&#34;&gt;balancing the deque&lt;/h2&gt;

&lt;p&gt;Based on &lt;a href=&#34;http://opendatastructures.org&#34;&gt;Open Data Structures&lt;/a&gt; [Mor], we
maintain the invariant stated above (neither stack falls below 3x the size of
the other). Before giving the implementation let us discuss the running
time. Clearly if we are going to carry out some sequence of operations on
stacks, adding and/or removing some multiple of N, then we are going to be left
with running time of O(N). This would be disastrous since we call &lt;code&gt;balance()&lt;/code&gt; on
each &lt;em&gt;enqueue/dequeue&lt;/em&gt; operation. It turns out though, that while the worst case running
time is O(N), the amortized running time is O(1). Stated another way, for M
enqueue/dequeue operations we will have running time in the order of O(M).&lt;/p&gt;

&lt;p&gt;For those familiar with the running time complexity analysis of dynamic
arrays, the above statement will not come as a surprise. For a more complete
analysis see [Mor].&lt;/p&gt;

&lt;p&gt;One method of balancing the stacks is by way of a couple of additional temporary
stacks and a sequence of &lt;em&gt;push&lt;/em&gt; and &lt;em&gt;pop&lt;/em&gt; operations.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// rebalance stacks
func (d *Deque) rebalance() {
	small, big := order(&amp;amp;d.front, &amp;amp;d.back)
	half := (small.len() + big.len()) / 2
	tmpB := &amp;amp;stack{}
	tmpS := &amp;amp;stack{}
	mvN(tmpB, big, half) // store half of big
	mvAll(tmpS, small)   // store small
	mvAll(small, big)    // put bottom half of big onto small
	mvAll(small, tmpS)   // restore small
	mvAll(big, tmpB)     // restore big
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned previously, &lt;code&gt;order()&lt;/code&gt; simply gives us the stacks back in order of size, the other helper
functions are;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// mvN: move n items from dst and push to src
func mvN(dst, src *stack, n int) {
	for i := 0; i &amp;lt; n; i++ {
		x, _ := src.pop()
		dst.push(x)
	}
}

// mvAll: move all items from src to dst
func mvAll(dst, src *stack) {
	mvN(dst, src, src.len())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See Github for complete
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/deques/twinStacks&#34;&gt;source code&lt;/a&gt; and tests.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Binary Search Tree in Golang</title>
      <link>/blog/bst/</link>
      <pubDate>Tue, 01 Nov 2016 11:37:27 +1100</pubDate>
      
      <guid>/blog/bst/</guid>
      <description>&lt;p&gt;A binary search tree (BST) is a binary tree where each node has a comparable key. As with
any tree, nodes may optionally contain satellite data.&lt;/p&gt;

&lt;p&gt;A BST can support many dynamic container operations, including search, minimum,
maximum, predecessor, successor, insert and delete. The defining feature of a
BST is that keys are maintained in an ordered fashion. This makes a BST a useful
data structure for implementing such things as ordered sets and bags.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;BST time complexity at worst case is O(&lt;em&gt;n&lt;/em&gt;), this occurs when the tree
is a linear chain of &lt;em&gt;n&lt;/em&gt; nodes. The expected height of a randomly built binary
tree is however &lt;em&gt;log n&lt;/em&gt;. This leads to the primary attraction of the BST, namely
that many operations have running time complexity of O(&lt;em&gt;log n&lt;/em&gt;). However, it is worth
keeping in mind the conditions that lead to worst case performance of a binary
tree. Building a tree from a sorted list of keys will produce worst case performance.&lt;/p&gt;

&lt;p&gt;The typical data structure used to implement a binary search tree found in the
literature as pseudo-code is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Node {
    integer key
    left Node
    right Node
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Translated into Go, with the addition of a parent node pointer to facilitate
more complex functionality, this becomes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Node struct {
    key    int
    left   *Node
    right  *Node
    parent *Node
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In beginning our discussion on binary search trees we will ignore satellite
data. This is justified by the fact that a BST with an integer key alone is
useful for many operations coupled with the fact that the addition of satellite
data involves only minor changes the underlying types.&lt;/p&gt;

&lt;p&gt;If one proceeds, using the above node type, to implement typical BST operations,
it will not be long before a subtle problem arises. If one attempts to create an
empty tree by starting with a zero value node &lt;code&gt;var n Node&lt;/code&gt; the tree will contain
a node with the key value of &lt;code&gt;0&lt;/code&gt;. This is because the zero value of a node is
equivalent to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var n Node
    n.key = 0
    n.left = nil
    n.right = nil
    n.parent = nil
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This may not be the desired behaviour. One solution presents itself from
this (overly explicit) snippet. An empty tree can be created using a node pointer instead
of a node &lt;code&gt;var n *Node&lt;/code&gt;. Another solution, and the one we will use henceforth,
is to wrap a pointer to the root node within another data structure&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Tree struct {
    root *Node
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This allows for the zero value of a Tree to be useful &lt;code&gt;var t Tree&lt;/code&gt;. It also
abstracts the details of an empty tree away from the user.&lt;/p&gt;

&lt;h2 id=&#34;tree-traversal&#34;&gt;Tree Traversal&lt;/h2&gt;

&lt;p&gt;It is common to visit the nodes of a binary tree in one of three manners,
pre-order, in-order, or post-order. As the names suggest, these involve visiting
the node before, between, or after visiting it&amp;rsquo;s children. For a BST with
integer keys, it is often most useful to utilise in-order tree traversal (tree
walk). Such a tree traversal will give the keys in ascending sorted order.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Walk tree in order calling fn for each node
func (n *Node) inorder(fn func(n *Node)) {
	if n != nil {
		n.left.inorder(fn)
		fn(n)
		n.right.inorder(fn)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using this function, and Go&amp;rsquo;s support for closures, we can do things like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Flatten: return inorder slice of keys
func (t *Tree) Flatten() []int {
	var keys []int
	fn := func(n *Node) {
		keys = append(keys, n.key)
	}
	t.root.inorder(fn)
	return keys
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Related to tree traversal are the operations minimum and maximum. By the formal
definition for the relation between the keys of a BST&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The keys in a binary search tree are always sorted. Let x be a node in a binary
search tree. If y is a node in the left subtree of x, then y.key &amp;lt; x.key. If y
is a node in the right subtree of x, then y.key &amp;gt;= x.key&lt;/em&gt; [CLRS09]&lt;/p&gt;

&lt;p&gt;the node with the maximum key value will be found in the right-most leaf of the
tree&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Max: return maximum key from tree
func (t *Tree) Max() (int, error) {
	if t.root == nil {
		return 0, fmt.Errorf(&amp;quot;Max() called on empty tree&amp;quot;)
	}
	n := t.root.max()
	return n.key, nil
}

// max: find node with maximum key from tree rooted at n
func (n *Node) max() *Node {
	for n.right != nil {
		n = n.right
	}
	return n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This shows one implication of using a separate Tree type. Methods may be
defined on Node types and/or on Tree types. For consistency Node methods will
return a node pointer giving us access to the node while Tree methods will
return the key value. Your millage may vary depending on the specific usage of
the tree. Minimum can be implemented in a similar fashion, for brevity it is
omitted but full source code can be found
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/trees/bsts/intKey/unique&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;insertion-and-deletion&#34;&gt;Insertion and Deletion&lt;/h2&gt;

&lt;p&gt;This section follows the algorithmic design outlined in &lt;em&gt;Introduction to
Algorithms&lt;/em&gt; [CLRS09]&lt;/p&gt;

&lt;p&gt;Insertion into a BST is simply a matter of locating the correct position and
inserting a new node. First we will create a new node with the requisite key&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// newNode: create a new node from key
func newNode(key int) *Node {
	var n Node
	n.key = key
	return &amp;amp;n
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can insert the node into the tree&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Add key to tree
func (t *Tree) Add(key int) {
	n := newNode(key)
	t.insert(n)
}

// insert node n into t
func (t *Tree) insert(new *Node) {
	if t.root == nil {
		t.root = new
		return
	}
	// find position
	var p *Node = nil
	n := t.root
	for n != nil {
	    p = n
	    if new.key &amp;lt; n.key {
		    n = n.left
	    } else {
		    n = n.right
	    }
	}
	// insert node
	if new.key &amp;lt; p.key {
		p.left = new
	} else {
		p.right = new
	}
	new.parent = p
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus far we have allowed multiple keys with the same value, this may or may not
be the required behaviour. It is however, trivial to transform one implementation to
the other, requiring only the addition of a check for equality between the new
nodes key and the current key&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    // ...
    for n != nil {
		p = n
		if new.key == n.key {
			return
		} else if new.key &amp;lt; n.key {
			n = n.left
		} else {
			n = n.right
		}
	}
    // ...

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Detion is somewhat more involved. One way to think about it is as
follows; if a node has no children it can safely be removed. If a node has only
children in one subtree it can be replaced by that subtree. If a node has two
children it&amp;rsquo;s successor must be found and used to replace the deleted node. Only
the last of these three cases presents any complexity. Firstly, let us get the
successor node to a key value that exists within the tree&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Successor: find smallest key value larger than key
// panic if key not present, ok if found
func (t *Tree) Successor(key int) (int, bool) {
	n := t.root.find(key)
	if n == nil {
		panic(&amp;quot;Succesor() called with non-existant key&amp;quot;)
	}
	next := n.successor()
	if next == nil {
		return 0, false
	}
	return next.key, true
}

// find node by key
func (n *Node) find(key int) *Node {
	for n != nil &amp;amp;&amp;amp; key != n.key {
		if key &amp;lt; n.key {
			n = n.left
		} else {
			n = n.right
		}
	}
	return n
}

// successor: return node with smallest key larger than n.key
func (n *Node) successor() *Node {
	if n.right != nil {
		return n.right.min()
	}
	p := n.parent
	for p != nil &amp;amp;&amp;amp; n == p.right {
		n = p
		p = p.parent
	}
	return p
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now returning to deletion. As stated it is not overly complex to remove a node
with zero or one child(ren). Let us now focus on the case of a node (n) with two
children.&lt;/p&gt;

&lt;p&gt;This can be split into two cases; firstly if the successor (s) of n is the
direct right child of n (this implies s has a nil left child) then s can be
&amp;lsquo;transplanted&amp;rsquo; into the position of n.&lt;/p&gt;

&lt;p&gt;If the successor is further down the right subtree of n then it must be further
moved. We can modify the right right subtree of n by removing s and creating a
tree with s as the root and the reaming nodes as the right child of s. Since the
successor is by definition the smallest of n&amp;rsquo;s right children this new tree
maintains correct structure. This tree can then be transplanted into position.&lt;/p&gt;

&lt;p&gt;The code to transplant a node is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// transplant replaces subtree rooted at u with subtree rooted at v
func (t *Tree) transplant(u, v *Node) {
	if u.parent == nil {
		t.root = v
	} else if u == u.parent.left {
		u.parent.left = v
	} else {
		u.parent.right = v
	}
	if v != nil {
		v.parent = u.parent
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We then wrap the call to Delete (by key) method around a call to delete (by Node),
easing later additions to the Tree type.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Delete node with key from tree
// true if deleted
func (t *Tree) Delete(key int) bool {
	n := t.root.find(key)
	if n == nil {
		return false
	}
	t.delete(n)
	return true
}

func (t *Tree) delete(d *Node) {
	if d.left == nil {
		t.transplant(d, d.right)
	} else if d.right == nil {
		t.transplant(d, d.left)
	} else {
		n := d.right.min()
		if n.parent != d {
			t.transplant(n, n.right)
			n.right = d.right
			n.right.parent = n
		}
		t.transplant(d, n)
		n.left = d.left
		n.left.parent = n
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Often when thinking about algoritms involving binary trees, recursive solutions
come to mind. And while many binary tree operations can be implemented in a
recursive manner some can be re-written in an iterative manner. Some however
cannot (e.g in-order tree walk). We must be careful to understand the
implications of calling recursive functions in a language that does not
implement tail call optimization. It is therefore sometimes prudent to consider an
iterative implementation as well as recursive. Here is one such function&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// elem: true if node with key exists in tree rooted at node n, recursive version
func (n *Node) elem(key int) bool {
	if n == nil {
		return false
	}
	if key == n.key {
		return true
	} else if key &amp;lt; n.key {
		return n.left.elem(key)
	}
	return n.right.elem(key)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And an iterative implementation&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// elem: true if node with key exists in tree rooted at node n, iterative version
func (n *Node) elem(key int) bool {
	found := false
	for {
		if n == nil {
			break // found = false
		}
		if n.key == key {
			found = true
			break
		}
		if key &amp;lt; n.key {
			n = n.left
		} else {
			n = n.right
		}
	}
	return found
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For full source code including additional operations (sum, size, height etc) see
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/trees/bsts/intKey/unique&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a final note, binary search trees can take many forms. If you have any
ideas on how I can better make use of search trees, or any comments at all,
please feel free to email me or submit a pull request.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[CLRS09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H.Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bag Data Structure in Golang</title>
      <link>/blog/bag/</link>
      <pubDate>Wed, 26 Oct 2016 10:49:04 +1100</pubDate>
      
      <guid>/blog/bag/</guid>
      <description>&lt;p&gt;A bag is a container of non-unique items. Bags are defined by the following
operations &lt;em&gt;Length&lt;/em&gt;, &lt;em&gt;Add&lt;/em&gt;, &lt;em&gt;Delete&lt;/em&gt; and &lt;em&gt;Find&lt;/em&gt;. Bags often also need to support
&lt;em&gt;FindAll&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Bags can be ordered or un-ordered. This post will be discussing un-ordered
bags.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Bags are useful when one needs to store a bunch of things and later check
if a certain thing is present. For example, storing the characters of a string
(and perhaps, the frequency count).&lt;/p&gt;

&lt;p&gt;A bag can be easily implemented in Go using a map.&lt;/p&gt;

&lt;h2 id=&#34;bag-of-integers&#34;&gt;bag of integers&lt;/h2&gt;

&lt;p&gt;For the sake of simplicity, we will first cover a bag of integers, then move
onto a bag of characters (including some useful functions on such a bag).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package bag

type count int

type Bag map[int]count

func (b *Bag) Len() int {
	sum := 0
	for _, v := range *b {
		sum += int(v)
	}
	return sum
}

func (b *Bag) Add(x int) {
	(*b)[x]++
}

func (b *Bag) Delete(x int) {
	_, ok := (*b)[x]
	if ok {
		(*b)[x]--
	}
}

func (b *Bag) Find(x int) (int, bool) {
	count, ok := (*b)[x]
	return int(count), ok
}

func (b *Bag) FindAll(x int) (int, bool) {
	return b.Find(x) // not useful for this implementation
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then use our bag of integers like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func fn() {
    bag := make(Bag)

	// add some values to bag
	for i := 0; i &amp;lt; 5; i++ {
		bag.Add(i)
    }

    // check if we have a &#39;2&#39;
    x, ok := bag.Find(2)  // x = 1 (one &#39;2&#39; in bag), ok = true

    // check if we have a &#39;10&#39;
    x, ok = bag.Find(10)  // ok = false (no &#39;10&#39; in bag)

    // add a second &#39;2&#39; and check we now have two of them in bag 
    bag.Add(2)
    x, ok := bag.Find(2)  // x = 2 (two 2&#39;s in bag), ok = true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bag-of-bytes&#34;&gt;bag of bytes&lt;/h2&gt;

&lt;p&gt;A bag of bytes can be used to store such things as byte values for characters
encoded using ASCII. This bag would not be very useful for storing text written
in Greek but would be useful for some cryptography tasks.&lt;/p&gt;

&lt;p&gt;The basic operations are similar to the above, except of course we replace
occurences of &lt;code&gt;int&lt;/code&gt; with &lt;code&gt;byte&lt;/code&gt;. Also we add a helper function to create a bag
from a string (ASCII values only remember).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Bag map[byte]int

func makeBag(s string) Bag {
	bag := make(Bag)
	for i := 0; i &amp;lt; len(s); i++ {
		bag.Add(s[i])
	}
	return bag
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then write some other functions to operate on this bag&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (b *Bag) difference(c Bag) Bag {
	bag := make(Bag)
	for k, vb := range *b {
		vc, ok := c[k]
		if ok {
			if vb &amp;gt; vc {
				bag[k] = vb - vc
			}
		} else {
			bag[k] = vb
		}
	}
	return bag
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, one can implement union, and intersection in the above manner. See
Github for complete
&lt;a href=&#34;https://github.com/tcharding/types/tree/master/bags&#34;&gt;source code&lt;/a&gt; and tests.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[CLRS09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H.Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Queue Data Structure in Golang</title>
      <link>/blog/queue/</link>
      <pubDate>Wed, 26 Oct 2016 09:54:21 +1100</pubDate>
      
      <guid>/blog/queue/</guid>
      <description>&lt;p&gt;A queue is a container that supports retrieval by first-in, first-out (FIFO)
order. The &lt;em&gt;get&lt;/em&gt; and &lt;em&gt;put&lt;/em&gt; operations for a queue are usually called &lt;em&gt;enqueue&lt;/em&gt; and
&lt;em&gt;dequeue&lt;/em&gt;, other operations may include &lt;em&gt;isEmpty&lt;/em&gt;. A full description of
queues can be found online &lt;a href=&#34;http://opendatastructures.org&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Queue&amp;rsquo;s minimise the maximum time spent waiting, however the average wait time
will be the same whether a LIFO or a FIFO is used.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;A queue can be easily implemented in Go using slices.&lt;/p&gt;

&lt;h2 id=&#34;queue-of-integers&#34;&gt;queue of integers&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;package queue

type Queue []int

func (q *Queue) Enqueue(x int) {
	*q = append(*q, x)
}

func (q *Queue) Dequeue() (int, bool) {
	if q.isEmpty() {
		return 0, false
	}

	x := (*q)[0]
	*q = (*q)[1:]
	return x, true
}

func (q *Queue) isEmpty() bool {
	return len(*q) == 0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then use our queue of integers like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func fn() {
    var q Queue

    q.Enque(1)
    q.Enque(2)
    q.Enque(3)

    x := q.Dequeue()  // x = 1
    x = q.Dequeue()   // x = 2
    x = q.Dequeue()   // x = 3
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;queue-of-structs&#34;&gt;queue of structs&lt;/h2&gt;

&lt;p&gt;Today I found a nice implementation of a Queue in the
&lt;a href=&#34;https://github.com/gonum/graph/blob/master/internal/linear/linear.go&#34;&gt;graph&lt;/a&gt;
package by the people at &lt;a href=&#34;https://github.com/gonum&#34;&gt;Gonum&lt;/a&gt;. I have stripped it
down to a queue of structs&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Queue implements a FIFO queue.
type Queue struct {
	head int
	data []item
}

// Item: real implementation would have something useful here.
type item struct {
	data string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;head&lt;/code&gt; is the index of the head of the queue. Length of the queue is then the
length of the data slice less the index of the head item.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Len returns the number of items in the queue.
func (q *Queue) Len() int { return len(q.data) - q.head }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to reuse the underlying array, when an item is enqueued, if there is
room at the front of the queue then we copy the current queue contents back to
the start of the array.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Enqueue adds the node n to the back of the queue.
func (q *Queue) Enqueue(n item) {
	if len(q.data) == cap(q.data) &amp;amp;&amp;amp; q.head &amp;gt; 0 {
		ln := q.Len()
		copy(q.data, q.data[q.head:])
		q.head = 0
		q.data = append(q.data[:ln], n)
	} else {
		q.data = append(q.data, n)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that arguments to copy may be overlapping, Go&amp;rsquo;s built in &lt;code&gt;copy&lt;/code&gt; allows
this. This is a nice efficiency tweak over the simple implementation given at
the start of this post. We now reduce the number of times that a new underlying
array is created.&lt;/p&gt;

&lt;p&gt;The memory usage of this implementation is quite different from the simple
queue. Like as is often the case with data structures, different data structures
may perform differently under different workloads, one is not necessarily better
than another.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[CLRS09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H.Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Stack Data Structure in Golang</title>
      <link>/blog/stack/</link>
      <pubDate>Mon, 17 Oct 2016 08:28:17 +1100</pubDate>
      
      <guid>/blog/stack/</guid>
      <description>&lt;p&gt;A stack is a container that supports retrieval by last-in, first-out (LIFO)
order. The &lt;em&gt;get&lt;/em&gt; and &lt;em&gt;put&lt;/em&gt; operations for stacks are usually called &lt;em&gt;push&lt;/em&gt; and
&lt;em&gt;pop&lt;/em&gt;, other operations may include &lt;em&gt;peek&lt;/em&gt; and &lt;em&gt;isEmpty&lt;/em&gt;. A full description of
stacks can be found online &lt;a href=&#34;http://opendatastructures.org&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Stacks are simple to implement and very efficient. For this reason, stacks are
probably the right container to use when retrieval order doesn&amp;rsquo;t matter [Ski08]&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A stack can be easily implemented in Go using slices.&lt;/p&gt;

&lt;h2 id=&#34;stack-of-integers&#34;&gt;stack of integers&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;// stack of integers
package stack

type Stack []int

// IsEmpty: check if stack is empty
func (s *Stack) IsEmpty() bool {
	return len(*s) == 0
}

// Push a new integer onto the stack
func (s *Stack) Push(x int) {
	*s = append(*s, x)
}

// Pop: remove and return top element of stack, return false if stack is empty
func (s *Stack) Pop() (int, bool) {
	if s.IsEmpty() {
		return 0, false
	}

	i := len(*s) - 1
	x := (*s)[i]
	*s = (*s)[:i]

	return x, true
}

// Peek: return top element of stack, return false if stack is empty
func (s *Stack) Peek() (int, bool) {
	if s.IsEmpty() {
		return 0, false
	}

	i := len(*s) - 1
	x := (*s)[i]

	return x, true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then use our stack of integers like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func fn() {
    var stack Stack

    stack.Push(1)
    stack.Push(2)
    stack.Push(3)

    x := stack.Peek()  // x = 3
    x = stack.Pop()    // x = 3
    x = stack.Peek()   // x = 2
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is trivial to replace integers with any other type
(&lt;a href=&#34;https://github.com/tcharding/types/tree/master/stacks/string&#34;&gt;string&lt;/a&gt;,
struct, etc).&lt;/p&gt;

&lt;h2 id=&#34;stack-of-anything&#34;&gt;stack of anything&lt;/h2&gt;

&lt;p&gt;One downside to the above method is that a new stack needs to be written for
each data type. An alternative is to use the empty interface to allow stacks of
anything.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// All types satisfy the empty interface, so we can store anything here.
type Stack []interface{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then any time we pop or peek at an item from the stack we use a type
assertion.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var stack Stack
stack.Push(&amp;quot;this&amp;quot;)

item := stack.Pop()
fmt.Printf(&amp;quot;%s\n&amp;quot;, item.(string))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This comes with the usual warnings that using the empty type interface reduces
the ability of the compiler to catch type errors, one of the benefits of using a
strongly typed language.&lt;/p&gt;

&lt;p&gt;Full source code is available &lt;a href=&#34;https://github.com/tcharding/types/tree/master/stacks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also Douglas Hall has done a nice stack implementation using linked lists instead of
slices. You can find his gist &lt;a href=&#34;https://gist.github.com/bemasher/1777766&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;bibliography&#34;&gt;Bibliography:&lt;/h4&gt;

&lt;p&gt;[Ski08] - &lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;, Steven S. Skiena&lt;br /&gt;
[CLRS09] - &lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;, Thomas H.Cormen, Charles E. Leiserson,
Ronald L. Rivest, Clifford Stein&lt;br /&gt;
[Mor] - &lt;strong&gt;Open Data Structures&lt;/strong&gt;, Pat Morin, Edition 0.1&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reading List</title>
      <link>/reading-list/</link>
      <pubDate>Sat, 15 Oct 2016 14:17:43 +1100</pubDate>
      
      <guid>/reading-list/</guid>
      <description>

&lt;p&gt;Past, current, and future. List is in approximate reverse chronological order.&lt;/p&gt;

&lt;h1 id=&#34;future&#34;&gt;Future&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Introduction to Graph Theory&lt;/strong&gt;
Richard J. Trudeau&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Linear Algebra and its Applications&lt;/strong&gt;
Gilbert Strang&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Flatland: A Romance of Many Dimensions&lt;/strong&gt;
Edwin Abbott Abbott&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Alchemist&lt;/strong&gt;
Paulo Coelho&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gdel, Escher, Bach: an Eternal Golden Braid&lt;/strong&gt;
Douglas R. Hofstadter&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Peopleware&lt;/strong&gt; Productive Projects and Teams -
Tom DeMarco and Timothy Lister&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Mythical Man-Month&lt;/strong&gt;
Frederick P. Brooks, Jr.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An Introduction to Functional Programming Systems Using Haskell&lt;/strong&gt;
A J T Davie&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mastering Regular Expressions&lt;/strong&gt;
Jeffrey E.F. Friedl&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hackers Delight&lt;/strong&gt;
Henry S. Warren, Jr.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Programming Pearls&lt;/strong&gt;
Jon Bently&lt;/p&gt;

&lt;h1 id=&#34;current&#34;&gt;Current&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Discrete and Combinatorial Mathematics&lt;/strong&gt;
Ralph P. Grimaldi&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open Data Structures&lt;/strong&gt;
Pat Morin&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Introduction to Algorithms&lt;/strong&gt;
Thomas H. Cormen, Charles C. Leiserson, Ronald L. Rivest, Clifford Stein&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Algorithm Design Manual&lt;/strong&gt;
Steven S Skiena&lt;/p&gt;

&lt;h1 id=&#34;past&#34;&gt;Past&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;The Go Programming Language&lt;/strong&gt;
Alan A. A. Donovan, Brian W. Kernighan&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Apprenticeship Patterns&lt;/strong&gt; Guidance for the Aspiring Software Craftsman -
David H. Hoover and Adewale Oshineye &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Real World Haskell&lt;/strong&gt;
Bryan O&amp;rsquo;Sullivan, John Goerzen and Don Stewart &lt;em&gt;(s,s)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learn You a Haskell For Great Good&lt;/strong&gt;
Miran Lipovaca &lt;em&gt;(m,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Structure and Interpretation of Computer Programs&lt;/strong&gt;
Harold Abelson, Gerald Jay Sussman, Julie Sussman &lt;em&gt;(m,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Scheme Programming Language&lt;/strong&gt;
R. Kent Dybvig &lt;em&gt;(m,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Little Schemer&lt;/strong&gt;
Daniel P. Friedman, Matthias Felleisen &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ARM Assembly Language&lt;/strong&gt;
William Hohl &lt;em&gt;(a,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Essential Linux Device Drivers&lt;/strong&gt;
Sreekrishnan Venkateswaran &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Linux Device Drivers&lt;/strong&gt;
Jonathan Corbet, Alessandro Rubini, Greg Kroah-Hartman &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Linux Kernel Develop&lt;/strong&gt;
Robert Love &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Linux Programming Interface&lt;/strong&gt;
Michael Kerrisk &lt;em&gt;(m,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Programming the World Wide&lt;/strong&gt;
Rebert W. Sebesta &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applied Cryptography&lt;/strong&gt;
Bruce Schneier &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Python Essential Reference&lt;/strong&gt;
David M. Beazley &lt;em&gt;(m,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Clean Code, A Handbook of Agile Software Craftsmanship&lt;/strong&gt;
Robert C. Martin &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Python the Hard Way&lt;/strong&gt;
Zed A. Shaw &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UNIX Network Programming&lt;/strong&gt;
W. Richard Stevens, Bill Fenner, Andrew M. Rudoff &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advanced Programming in the UNIX Environment&lt;/strong&gt;
W. Richard Stevens, Stephen A. Rago &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UNIX Systems Programming&lt;/strong&gt;
Kay A. Robbins, Steven Robbins &lt;em&gt;(a,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Intermediate Perl&lt;/strong&gt;
Randal L. Schwartz, brian d foy, Tom Phoenix &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning Perl&lt;/strong&gt;
Randal L. Schwartz, brian d foy, Tom Phoenix &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Beginning Linux Programming&lt;/strong&gt;
Neil Matthew, Richard Stones &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Version Control with Git&lt;/strong&gt;
Jon Loeliger, Matthew McCullough &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Pragmatic Programmer&lt;/strong&gt;
Andrew Hunt, David Thomas &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Art of UNIX Programming&lt;/strong&gt;
Eric S. Raymond &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expert C Programming, Deep C Secrets&lt;/strong&gt;
Peter Van Der Linden &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Practice of Programming&lt;/strong&gt;
Brian W. Kernighan, Rob Pike &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How Linux Works&lt;/strong&gt;
Brian Ward &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning GNU Emacs&lt;/strong&gt;
Debra Cameron, James Elliott, Marc Loy, Eric Raymond, Bill Rosenblatt &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Art of Computer Programming (volume 2)&lt;/strong&gt; Seminumerical Algorithms -
Donald E. Knuth &lt;em&gt;(m,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Art of Computer Programming (volume 1)&lt;/strong&gt; Fundamental Algorithms -
Donald E. Knuth &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Command Line Kung Foo&lt;/strong&gt;
Jason Cannon &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Linux Shell Scripting with Bash&lt;/strong&gt;
Ken O. Burtch &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;From Bash to Z Shell&lt;/strong&gt; Conquering the Command -
Oliver Kiddle, Jerry Peek, Peter Stephenson &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computer Networks&lt;/strong&gt; A Systems Approach -
Larry L. Peterson, Bruce S. Davie &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A Concise Introduction to Pure Mathematics&lt;/strong&gt;
Martin Liebeck &lt;em&gt;(m,m)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computer Organization and Design&lt;/strong&gt;
David A. Patterson, John L Hennessy &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Operating System Concepts&lt;/strong&gt;
Abraham Silberschatz, Peter Baer Galvin, Greg Cagne &lt;em&gt;(a,-)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The C Programming Language&lt;/strong&gt;
Brian W. Kernighan, Dennis Ritchie &lt;em&gt;(a,a)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Past reading entries are suffixed with code representing level of
completion. First character representing amount of
text read. Second character representing amount of exercises
completed.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key:&lt;/strong&gt; &lt;em&gt;(x,x)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;s = some&lt;br /&gt;
m = most&lt;br /&gt;
a = all&lt;br /&gt;
- = not applicable (i.e no exercises in text)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>initial commit</title>
      <link>/blog/initial-commit/</link>
      <pubDate>Tue, 11 Oct 2016 22:10:57 +1100</pubDate>
      
      <guid>/blog/initial-commit/</guid>
      <description>&lt;p&gt;According to &lt;strong&gt;Apprenticeship Patterns&lt;/strong&gt; by Bavid H. Hoover and Adewale Oshineye,
in order to become a journeyman one must learn to explain their craft to
others. This is one apprentices effort to learn these skills.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>/about-me/</link>
      <pubDate>Tue, 11 Oct 2016 21:59:47 +1100</pubDate>
      
      <guid>/about-me/</guid>
      <description>&lt;p&gt;Hello people, I am &lt;strong&gt;Tobin Harding&lt;/strong&gt;. I code in the Linux environment. I like
command line interfaces and statically typed languages. When I am trying to
relax I listen to classical music, when eating jazz, and when getting excitable
I like to listen to techno.  I like learning things, mostly computer related
things but also violin. For health and giggles I surf, do yoga, ferment, and
grow vegetables. I am an apprentice programmer, my primary language is Go.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>